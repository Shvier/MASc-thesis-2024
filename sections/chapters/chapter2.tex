\chapter{Preliminaries and Related Work}

\section{Accounting Terminology}

Our terminology follows the accounting and auditing literature. A balance sheet consists of liabilities (value owed to others) and assets (value owned). When total asset value is the same or more than total liabilities, the firm is called solvent. The amount by which the assets exceed the liabilities is called capital or equity (depending on context). Some literature prefers the term `proof of reserves' to `proof of solvency.' This terminology is also sound, although it is not always defined correctly: technically a reserve is an asset that cancels out a corresponding liability, both in amount and in type. A firm can be solvent but not have full reserves. Most banks operate this way with cash liabilities, some assets in cash, but most assets in loans and other investments.\footnote{Banks in the United States have reserve requirements while banks elsewhere, \eg Canada, have capital requirements. Capital requirements speak to solvency, while reserve requirements speak to reserve ratios. Banks that underwent the 2008 financial crisis were more robust when they had capital requirements, as opposed to reserve requirements.} Cryptographic protocols in the literature generally assume both liabilities and assets are the same cryptocurrency so exchanges are expected to be both solvent and have full reserves.

\section{Related Work}
\label{sec:rw}

\input{sections/tables/comp}

Proofs of solvency began as a discussion on Bitcointalk, where a protocol was developed for an exchange to announce a commitment to a total liability, and offer a Merkle-tree proof to each user that their balance was reflected in this total liability amount. Provisions, a research paper, used homomorphic commitments and $\Sigma$-protocols to add zero-knowledge, plus it added a proof of assets that could be used with the proof of liabilities to prove overall solvency~\cite{provisions}. As Provisions relies heavily on range proofs for liabilities, Bulletproofs can reduce the proof size of Provisions by 300x~\cite{bulletproofs}. Our protocol uses a polynomial-based range proof~\cite{rangeproof} to further reduce proof size and verifier time.

Outside of Provisions, Bulletproofs, and \Sys, the vast majority of work on proofs of solvency have not attempted an end-to-end proof, focusing instead on just the liabilities or just the assets. Why? We hypothesize that the biggest impediment is that Bitcoin and Ethereum assets are controlled by \secp private keys (see Table~\ref{tab:rb1}). Outside of Bulletproofs (based on inner-product arguments that do not require bilinear pairings and thus, can be implemented in \secp), most other approaches to succinctness require a specific cryptographic setting that is not \secp (\ie RSA for accumulators, pairing-based cryptography for zk-SNARKs, and lattices for zk-STARKs). If one only considers liabilities, then this problem does not have to be dealt with.

Circuit-based solutions are feasible but expensive for the prover---the authors of IZPR report about 500K constraints needed per key and proving times in the order of days for an anonymity set of 6000 keys~\cite{izpr}. By contrast, \Sys is a few minutes of work for the prover for 6000 keys. As this part is not-succinct (it is based on $\Sigma$-protocols), the trade-off is that the verifier has to do a few minutes of work as well. In both cases, IZPR and \Sys, this step does not need to be repeated often, only when the exchange wants to introduce new keys holding its assets. It is also important to recognize IZPR can let the exchange add keys it has not used yet to $\pi_{keys}$, further reducing how often this proof needs to be redone. This is a desirable property we are not able to easily achieve in \Sys (in short, it is due to our  use of selector polynomials instead of lookup arguments but future work could explore blending the best properties of \Sys and IZPR). 

% = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =

\section{Cryptographic Background}

We assume our protocol works on a finite field of prime order. For simplicity, we use $\prv$ and $\vrf$ to denote the prover and the verifier in an interactive proof system respectively. We use $g_\mathfrak{g}$ to denote a generator in a group $\mathbb{G}_\mathfrak{g}$ while $h_\mathfrak{g}$ is another generator, and no one knows the relative discrete logarithm of these two generators. Particularly, we use $\gs$ and $\hs$ to denote the two generators in $\mathbb{G}_s$, the \secp group; and we use $\gb$ and $\hb$ to denote the two generators in $\mathbb{G}_b$, the \bls group. If we need to distinguish which group an input to the pairing is from, we use the notations $[x]_1:=g_1^x,[x]_2:=g_2^x$, otherwise elements are  assumed to be in the first group (including $g_s$ and $g_b$). We use $e([x]_1,[x]_2)$ to denote a non-degenerate bilinear pairing. We use $\hash$ to denote a collision-resilient hash function modelled as a random oracle. We use $\ppt$ to represent probabilistic algorithms run in polynomial time.  For vectors, we use an overhead bar to denote a vector and brackets to denote the elements in this vector, e.g., $\overline{v}=\tuple{v_1,v_2,\dots}$. We also use a vector at the top right of a variable to indicate this variable belongs to this vector for readability, e.g., $x^{(\overline{v})}$ means $x$ is an element of $\overline{v}$. When we say the summation between two vectors $\overline{a},\overline{b}$, the result is a new vector $\overline{c}$ where each element is the summation of the elements from $\overline{a}$ and $\overline{b}$ at the same row.

\subsection{Discrete Logarithm Assumption}
\label{sec:dlp}
The discrete logarithm problem describes, given a triplet $(\mathbb{G}, p, g)$, where $\mathbb{G}$ is a cyclic group of order $p$ generated by $g\in\mathbb{G}$, and an element $y\in\mathbb{G}$, for a given adversary $\mathcal{A}$, $\mathcal{A}$ needs to compute an $x$ such that $y=g^x$. The discrete logarithm assumption holds for $\mathbb{G}$ if it is infeasible for $\mathcal{A}$ to find such $x$ in polynomial time.

\subsection{Pedersen Commitment}
\label{sec:pedersen}
The Pedersen commitment scheme \cite{pedersen} enables $\prv$ to \textit{commit} to a value $x$ without revealing it. Pedersen commitment provides perfectly hiding and computational binding based on the discrete logarithm assumption. Additionally, Pedersen commitments are \textit{additively homomorphic}: given two commitments $\textbf{C}_1$ and $\textbf{C}_2$, the summation of their secrets $x_1$ and $x_2$ is the secret of $\textbf{C}_1\cdot\textbf{C}_2$. We use $\textbf{C}(x)$ to denote a Pedersen commitment to the value $x$. Particularly, we use $\ps$ to denote a Pedersen commitment in \secp and $\pb$ to denote a Pedersen commitment in \bls.

\subsection{Zero-Knowledge Proofs}
Informally, a zero-knowledge proof is a cryptographic protocol allowing $\prv$ to convince $\vrf$ that the claiming statement is true without revealing additional information, except the fact that the statement's truth. A zero-knowledge proof must satisfy the following properties:
\begin{enumerate}
    \item \textbf{Completeness:} If the statement is true, $\vrf$ will be convinced.
    \item \textbf{Soundness:} If the statement is false, the probability that $\vrf$ is convinced is negligible.
    \item \textbf{Zero-knowledge:} If the statement is true, $\vrf$ learns nothing except the fact that the statement is true.
\end{enumerate}
It is worth noting there are different definitions for the soundness (special soundness, knowledge soundness in algebraic group model) and the zero knowledge (honset verifier zero knowledge, special honest verifier zero knowledge) in the context of some protocols. We refer to~\ref{} for more detailed explanations.

\subsection{$\Sigma$-Protocol}

The $\Sigma-$protocol is a three-move interactive proof system. We define the $\Sigma-$protocol similarly to \cite{damgard10}.
\begin{definition} 
\label{sec:sigma}
Let $R$ be a binary relation between the statement $x$ and the witness $w$. Given common input $x$ to $\prv$\ and $\vrf$, and private input $(x,w)$ such that $(x,w)\in{R}$ to $\prv$, they run the following protocol:
\begin{enumerate}
    \item $\prv$ computes a message $m$ from $(x,w)$ and sends $m$.
    \item $\vrf$ sends a random challenge $c$.
    \item $\prv$ replies with $z$.
\end{enumerate}
At the end of the protocol $\vrf$ has the data $(x,m,c,z)$. He decides to output \textbf{acc} or \textbf{rej}; such that
\begin{itemize}
    \item \textbf{Completeness}: If $\prv$ follows the protocol to generate the message $(m,c,z)$, $\vrf$ always accepts.
    \item \textbf{Special soundness}: If there exists a $\ppt$ extractor $\mathcal{E}$, given any input $x$ and any two accepting $(m,c,z),(m,c^\prime,z^\prime)$ where $c\ne{c^\prime}$, $\mathcal{E}$ can compute $w$ where $(x,w)\in{R}$.
    \item \textbf{HVZK}: If there exists a $\ppt$ simulator $\mathcal{S}$, such that the transcript produced by $\mathcal{S}$ is indistinguishable from the messages between $\prv$ and $\vrf$.
\end{itemize}
\end{definition}
A commonly well-known way to convert a $\Sigma-$protocol into non-interactive is using the Fiat-Shamir transform \cite{fs}. But we still use the standard interactive $\Sigma-$protocol to demonstrate our work for comprehension.

\subsection{Disjunction of $\Sigma$-Protocols (OR Proof)}
The disjunction of $\Sigma$-protocols (OR proof) allows $\prv$ to prove the claimed $x$ is $x_1$ or $x_2$ through a $\Sigma$-protocol. More precisely, given two inputs $x_1,x_2$, $\prv$ proves he knows a $w$ such that $(x_1,w)\in{R_1}$ or $(x_2,w)\in{R_2}$, but $\vrf$ cannot learn which one $\prv$ knows. We use the same definition as \cite{damgard10}.
\begin{definition}
Let $s$ equal $0$ or $1$. The OR proof is a $\Sigma-$protocol that $\prv$ and $\vrf$ are given two public inputs $x_1,x_2$, and $\prv$ is given $w$ as private input. They run the following protocol:
\begin{enumerate}
    \item $\prv$ computes the message $m_s$ using $(x_s,w)$ as input. \\
    $\prv$ randomly generates $c_{1-s}$ as the challenge for $x_{1-s}$ and runs the simulator $\mathcal{S}(x_{1-s},c_{1-s})$ to produce $(m_{1-s},z_{1-s})$.
    \item $\prv$ sends $m_s$ and $m_{1-s}$.
    \item $\vrf$ sends a master challenge $c$.
    \item $\prv$ computes $c_s=c\oplus{c_{1-s}}$ and $z_s$ on inputs $(x_s,c_s,m_s,w)$. \\
    $\prv$ sends $(c_s,c_{1-s},z_s,z_{1-s})$.
\end{enumerate}
At the end of the protocol $\vrf$ verifies $c=c_s\oplus{c_{1-s}}$ and both $(m_s,c_s,z_s,x_s)$ and $(m_{1-s},c_{1-s},z_{1-s},x_{1-s})$ are valid to output \textbf{acc} or \textbf{rej}; such that
\begin{itemize}
    \item \textbf{Completeness:} The case of $c_{1-s}$ is always accepted by $\vrf$ as the definition of a simulator; on the other side, the case of $c_s$ has no difference from the standard $\Sigma-$protocol.
    \item \textbf{Special soundness:} Let $\prv$ execute the protocol twice. Two accepting transcripts
    \[ (x_s,x_{1-s},c,c_s,c_{1-s},z_s,z_{1-s}),(x_s,x_{1-s},c^\prime,c_s^\prime,c_{1-s}^\prime,z_s^\prime,z_{1-s}^\prime),c\ne{c^\prime} \] 
    are given. It is clear that for some $s=0$ or $1$, the witness $w$ such that $(x_s,w)\in{R}$ can be extracted through an extractor $\mathcal{E}$ by the special soundness of $\Sigma$-protocol.
    \item \textbf{Special HVZK}: Given a master challenge $c$, let $\mathcal{S}$ choose $c_s$ or $c_{1-s}$ randomly and the other will be determined. Then let the simulator run twice: $\mathcal{S}(x_s,c_s),\mathcal{S}(x_{1-s},c_{1-s})$, to output $(m_s,z_s,m_{1-s},z_{1-s})$. The outputs of $\mathcal{S}$ have the same distribution as those of $\prv$.
\end{itemize}
\end{definition}
We use $x={x_1\orproof{x_2}}$ to denote $x$ is $x_1$ or $x_2$.

\subsection{Roots of Unity}
\label{app:rou}

\begin{figure}
\centering
\includegraphics[width=\textwidth]{roots}
\caption{Small number ($\mathbb{Z}_{31}$) example of encoding a vector of integers $\tuple{3,1,1,3,7}$ into (a) the first 5 points of a polynomial, and (b) into 5th roots of unity ($\omega=3$).\label{fig:rou}}
\end{figure}

We use the approach of encoding data vectors into polynomials, committing to them using a polynomial commitment scheme (PCS), and forming zero knowledge arguments---a model called a polynomial-based interactive oracle proof (Poly-IOP). The zk-snark system Plonk popularized Poly-IOPs and has many extensions and optimizations. A one-dimensional vector of data is encoded into a univariate polynomial using 1 of 3 methods (all 3 are used at different steps of Plonk): (1) into the coefficients of the polynomial, (2) as roots of the polynomial, and (3) as the \(y\)-coordinates (\(\mathsf{data}_i=p(x_i)\)) of points on the polynomial. Plonk mostly relies on (3) and an interpolation algorithm is used to find the corresponding coefficients of the polynomial, which is
needed for the PCS. General interpolation algorithms are \(O(n^2)\) work for \(n\) evaluation points but this can be reduced to \(O(n\log n)\) with an optimization.

The optimization enables interpolation via the fast Fourier transform (FFT). It concerns how to choose the \(x\)-coordinates, which will serve as the index for accessing the data: evaluating \(p(X)\) at \(x_i\) will reveal \(\mathsf{data}_i\). First note, \(x\)-coordinates are from the exponent group (\(\mathbb{Z}_q\)) and the choices exceed what is feasible to use (\(2^{255}\) values in \bls). Any subset can be used and interpolated. The optimization is to chose them with a mathematical structure. Specifically, instead an additive sequence (e.g., \(0,1,2,3,\ldots\)), we use a multiplicative sequence
\(1,\omega,\omega\cdot\omega,\omega\cdot\omega\cdot\omega,\ldots\) or equivalently: \(\omega^0,\omega^1,\omega^2,\ldots,\omega^{\kappa-1}\). Further, the sequence is closed under multiplication which means that next index after \(\omega^{\kappa-1}\) wraps back to the first index: \(\omega^{k-1} \cdot \omega = \omega^\kappa = \omega^0=1\) (this property is also useful in proving relationships between data in the vector and its neighbouring values).

For terminology, we say \(\omega\) is a generator with multiplicative order \(\kappa\) in \(\mathbb{Z}_q\). This implies \(\omega^\kappa=1\). Rearranging, \(\omega=\sqrt[\kappa]{1}\). Thus we can equivalently describe \(\omega\) as a \(\kappa\)-th root of 1. Finally, as 1 is the unity element in \(\mathbb{Z}_q\), \(\omega\) is commonly called a \(\kappa\)-th root of unity.

For practical purposes, \(\kappa\) represents the length of the longest vector of data we can use in our protocol. Where does \(\kappa\) come from? Different elements of \(\mathbb{Z}_q\) will have different multiplicative orders but every order must be a divisor of \(q-1\). Thus \(\kappa\) is the largest divisor of the exact value of \(q\) used in an elliptic curve standard. The value of $q$ in \bls has \(\kappa=2^{32}\) (for terminology, this called a \(2\)-adicity of \(32\)).

\subsection{Polynomial Commitment Scheme}
A polynomial commitment scheme (PCS) allows $\prv$ to commit to a polynomial to convince $\vrf$ that claimed evaluations are of the committed polynomial. Particularly, our protocol requires the scheme uses an extra random polynomial to achieve unconditionally binding, i.e., the KZG commitment in Pedersen form. We define the following scheme based on \cite{kzg,plonk,bdfg}.
\begin{definition}
\label{def:pcs}
A polynomial commitment scheme consists of three moves: \textbf{gen}, \textbf{com}, and \textbf{open} such that
\begin{enumerate}
    \item \textbf{gen}$(d)$ is an algorithm that given a random number $\tau\in\mathbb{F}$ and a positive integer d, outputs a structured reference string (SRS) \textbf{srs} such that
    \[ \textbf{srs}=\tuple{g_1,g_1^\tau,\dots,g_1^{\tau^d},h_1,h_1^\tau,\dots,h_1^{\tau^d},g_2,g_2^\tau} \]
    \item \textbf{com}($f$, \textbf{srs}) outputs a commitment $\cm=g_1^{f(\tau)}h_1^{\hat{f}(\tau)}$ to $f$, where $\hat{f}$ is a random polynomial of degree $d$, and $f$ is a polynomial of degree $d$ or less.
    \item \textbf{open} is a protocol that $\prv$ is given input f, and $\prv$ and $\vrf$ are both given
    \begin{itemize}
        \item \textbf{srs}
        \item $\cm$ - the commitment to $f$
        \item $a$ - an evaluation point of $f$
        \item $b$ - the evaluation of $f(a)$
        \item $\hat{b}$ - the evaluation of $\hat{f}(a)$
    \end{itemize}
    \textit{They run the protocol as follows:}
    \begin{enumerate}
        \item $\prv$ computes the witness $w$ for $(a,b,\hat{b})$ such that
        \[ w=g_1^{\psi(\tau)}h_1^{\hat\psi(\tau)} \]
        where $\psi(x)=\frac{f(X)-f(a)}{X-a}$, and $\hat\psi(x)=\frac{\hat{f}(X)-\hat{f}(a)}{X-a}$
        \item $\vrf$ outputs \textbf{acc} if and only if
        \[ e(\cm/(g_1^bh_1^{\hat{b}}),[1]_2)=e(w,[\tau-a]_2) \]
    \end{enumerate}
\end{enumerate}
\begin{itemize}
    \item \textbf{Completeness}: It is clear that $w$ exists if and only if $f(a)=b$ and $\hat{f}(a)=\hat{b}$, which means $\vrf$ always accepts the proof if $\prv$ follows the protocol.
    \item \textbf{Knowledge soundness in the algebraic group model}: For any algebraic adversary $\mathcal{A}$ in an interactive protocol of PCS, there exists a $\ppt$ extractor $\mathcal{E}$ given access to $\mathcal{A}$'s messages during the protocol, and $\mathcal{A}$ can win the following game with negligible probability:
    \begin{enumerate}
        \item Given the inputs that $\prv$ \textit{can access, $\mathcal{A}$ outputs} $\cm$.
        \item $\mathcal{E}$ outputs $f\in\mathbb{F}_{<d}[X]$ from $\mathcal{A}$'s output.
        \item $\mathcal{A}$ generates $w$ and $b^\prime$ at a random evaluation point $a$.
        \item $\mathcal{A}$ wins if
        \begin{itemize}
            \item $\vrf$ accepts the proof at the end of the protocol.
            \item $b^\prime\ne{b}$.
        \end{itemize}
    \end{enumerate}
\end{itemize}
\end{definition}
Our work uses PCS with the roots of unity. We use $\omega$ to denote the roots of unity. We use $\cm_f$ to denote a polynomial commitment to $f$ in Pedersen form.

\subsection{Range Proof}
\label{sec:range}

A range proof enables $\prv$ to convince $\vrf$ a value $x$ is in a specified range, e.g., $[0,2^k)$, without revealing $x$. Zero-knowledge range proofs (ZKRPs) have three typical approaches: square decomposition, $n$-ary decomposition, and hash chains~\cite{zkrp}. We use the polynomial-based range proof from Boneh \etal~\cite{rangeproof}.
\begin{enumerate}
    \item \textit{Given input $x$, $\prv$ decomposes $x$ to a vector of binary digits $\overline{z}=\tuple{z_1,z_2,\dots,z_k}$, so that $x=\sum_{i=0}^{k-1}2^i\cdot{z_i}$} 
    \item \textit{$\prv$ constructs a vector $\overline{x}=\tuple{x_1,x_2,\dots,x_k}$ such that}
    \begin{align*}
        x_1&=x \\
        x_k&=z_k \\
        x_i&=2x_{i+1}+z_i,i\in[1,k-1]
    \end{align*}
    \item \textit{$\prv$ interpolates a polynomial $f$ from $\overline{x}$ over a finite field $H$ of order $n$ with elements $\omega^0,\omega^1,\omega^2,\ldots,\omega^{n-1}$} 
    \item \textit{$\prv$ proves the following polynomials are vanishing in $H$}
    \begin{align*}
        w_1&:=[f(X)-x]\cdot\frac{X^n-1}{X-\omega^0} \\
        w_2&:=f(X)\cdot[f(X)-1]\cdot\frac{X^n-1}{X-\omega^{n-1}} \\
        w_3&:=[f(X)-2\cdot{f(X\omega)}]\cdot[f(X)-2\cdot{f(X\omega)}-1]\cdot(X-\omega^{n-1})
    \end{align*}
    \begin{enumerate}
        \item $\prv$ \textit{sends the commitment to $f(X)$}
        \item $\vrf$ \textit{sends a random challenge $\gamma$}
        \item $\prv$ \textit{sends the commitment to $q(X)=w/(X^n-1)$, such that}
        \[ w=w_1+\gamma\cdot{w_2}+\gamma^2\cdot{w_3} \]
        \item $\vrf$ \textit{sends a random evaluation point $\zeta\in\mathbb{F}$}
        \item $\prv$ \textit{replies with $f(\zeta),f(\zeta\omega),q(\zeta)$}
        \item $\vrf$ \textit{checks}
        \begin{enumerate}
            \item $w(\zeta)=q(\zeta)\cdot(\zeta^n-1)$
            \item $f(\zeta),f(\zeta\omega),q(\zeta)$ \textit{are the correct evaluations through the verifying process of KZG}
        \end{enumerate}
    \end{enumerate}
\end{enumerate}

\begin{lemma}
\label{lemma:range}
The range proof from Boneh \etal~\cite{rangeproof} is complete and has knowledge soundness in the algebraic group model.
\end{lemma}

\begin{proof}
Completeness is clear by following the protocol.

For knowledge soundness, to make the equation $w(\zeta)=q(\zeta)\cdot(\zeta^n-1)$ hold, $q(X)$ must exist (it is a rational function). That means $w(X)$ is vanishing on $H$, i.e., $w_1,w_2$, and $w_3$ are vanishing over $H$. Thus, if $f(X)$ does not satisfy any of the equations $w_1,w_2$, and $w_3$, $\vrf$ will detect the proof is invalid. By the binding property of KZG commitment, we know that the evaluations $f(\zeta),f(\zeta\omega)$, and $q(\zeta)$ are correct with overwhelmingly high probability if the KZG verifying is passed.
\end{proof}
We note that the above range proof is not zero-knowledge because (i) revealing $f(X)$ and $f(X\omega)$ leaks the evaluations of $f$ and (ii) verifying $w_1$ requires $\vrf$ to know $x$. The solutions for these two points may seem similar but not quite the same, because the first point requires $\prv$ not to open the evaluations of $f(X)$ over $H$, and the second point means $\prv$ is supposed to reveal the evaluation of $f(\omega^0)$ to prove $x$ is the claimed one. Boneh \etal~\cite{rangeproof} introduced a zero-knowledge extension to solve the first issue. We will describe the extension and manipulate a variant of the opening scheme to solve the second one.

\subsection{Batched Opening with Zero-Knowledge Extension ($\openzk$)}
\label{sec:kgzzkp}
To efficiently prove several polynomials are vanishing at several points, there are some batched KZG opening schemes such as the schemes in \cite{plonk,bdfg,fflonk}. Here, we use the batched opening scheme from~\cite{plonk} with the zero-knowledge extension from~\cite{rangeproof} to explain how to prove the range-proof polynomials are vanishing efficiently and in zero-knowledge. \\
\textit{Assume $\prv$ is given $x$ and $\prv$ computes $f(X)$ using the above range proof. $\prv$ wants to prove $f(X)$ satisfies the second and the third condition, i.e., $w_2$ and $w_3$ are vanishing over $H$:}
\begin{enumerate}
    \item $\prv$ \textit{generates two random numbers $\omega^{\prime},\omega^{\prime\prime}\in\mathbb{F}\setminus{H}$ and another two random numbers $\alpha,\beta\in\mathbb{F}$}
    \item $\prv$ \textit{interpolates $f$ at two more points ${\omega^{\prime},\omega^{\prime\prime}}$ such that}
    \[ f(\omega^{\prime})=\alpha \]
    \[ f(\omega^{\prime\prime})=\beta \]
    \textit{The new polynomial is called $f^\prime$.}
    \item $\prv$ \textit{computes $w_2$ and $w_3$ following the above range proof and sends the commitment to $f^\prime$,} $\cm_{f^\prime}$
    \item $\vrf$ \textit{sends a random challenge $\gamma\in\mathbb{F}$}
    \item $\prv$ \textit{sends the commitment to $q_w:=w/(X^n-1)$ where}
    \[ w:=w_2+\gamma\cdot{w_3} \]
    \item $\vrf$ \textit{sends a random evaluation point $\zeta\in\mathbb{F}\setminus{H}$}
    \item $\prv$ \textit{sends the evaluations $f^\prime(\zeta),f^\prime(\zeta\omega),q_w(\zeta)$}
    \item $\prv$ \textit{sends the commitments to $q_1(X),q_2(X)$, where}
    \[ q_1(X):=\frac{f^\prime(X)-f^\prime(\zeta)}{X-\zeta}+\gamma\cdot\frac{q_w(X)-q_w(\zeta)}{X-\zeta} \]
    \[ q_2(X):=\frac{f^\prime(X)-f^\prime(\zeta\omega)}{X-\zeta\omega} \]
    \item $\vrf$ \textit{chooses random $r\in\mathbb{F}$}
    \item $\vrf$ \textit{accepts the proof if and only if}
    \begin{enumerate}
    	\item $w_1(\zeta)+\gamma\cdot{w_2(\zeta)}=q_w(\zeta)\cdot(\zeta^n-1)$
    	\item $e(F+\zeta\cdot\cm_{q_1}+r\zeta\omega\cdot\cm_{q_2},[1]_2)=e(\cm_{q_1}+r\cdot\cm_{q_2},[x]_2)$\textit{, where}
    	\begin{align*}
    		F:=&\cm_{f^\prime}-[f^\prime(\zeta)]_1+\gamma\cdot(\cm_{q_w}-[q_w(\zeta)]_1)+r\cdot(\cm_{f^\prime}-[f^\prime(\zeta\omega)]_1)
    	\end{align*}
    \end{enumerate}
\end{enumerate}

\begin{theorem}
The batched KZG opening scheme with the zero-knowledge extension is complete, sound, and HVZK.
\end{theorem}
\begin{proof}
Completeness is clear by following the protocol. Soundness can be verified by Lemma~\ref{lemma:range} and~\cite{plonk}. \\
To verify zero knowledge, we construct a simulator $\mathcal{S}$. Let $\mathcal{S}$ randomly generate $\{\omega^{*^\prime},\omega^{*^{\prime\prime}},\alpha^*,\beta^*\}$ like $\prv$, and interpolate $f^*$ such that
\[ f^*(\omega^{*^\prime})=\alpha^* \]
\[ f^*(\omega^{*^{\prime\prime}})=\beta^* \]
\[ f^*(x)=0,x\in{H} \]
We can observe when $\vrf$ interacts with $\mathcal{S}$ to execute the protocol, $\vrf$ always accepts the proof from $\mathcal{S}$. Given $\{\omega^{*^\prime},\omega^{*^{\prime\prime}},\alpha^*,\beta^*\}$ are chosen uniformly at random each time, that is excatly the same as $\prv$ interpolates $f^\prime$. It should be clear $\vrf$ cannot distinguish between the transcript from $\mathcal{S}$ and the transcript from $\prv$.
\end{proof}
We will use $\openzk$ to denote this opening technique.

\subsection{Open KZG with Committed Value}
\label{sec:kzgOpenComm}
By Definition~\ref{def:pcs}, to prove $b$ is the evaluation of $f(a)$, $\prv$ reveals the pair $(a,b)$ to let $\vrf$ validate the proof through pairings. To solve the second issue in the above range proof, we describe the new opening scheme.
\begin{definition}
$\openc$ is a KZG opening scheme that $\prv$ is given input $f$ and $b$. $\prv$ and $\vrf$ are both given
\begin{itemize}
    \item \textbf{srs} = $\tuple{g_1,g_1^\tau,\dots,g_1^{\tau^d},h_1,h_1^\tau,\dots,h_1^{\tau^d},g_2,g_2^\tau}$
    \item $\cm$ - the commitment to $f$
    \item $a$ - an evaluation point of $f$
    \item $\textbf{C}(b)$ - the committed evaluation of $f(a)$, $g_1^{f(a)}h_1^{\hat{f}(a)}$
\end{itemize}
\textit{They run the protocol as follows:}
\begin{enumerate}
    \item $\prv$ computes the witness $w$ for $(a,b,\hat{b})$ such that
    \[ w=g_1^{\psi(\tau)}h_1^{\hat\psi(\tau)} \]
    where $\psi(x)=\frac{f(X)-f(a)}{X-a}$, and $\hat\psi(x)=\frac{\hat{f}(X)-\hat{f}(a)}{X-a}$
    \item $\vrf$ outputs \textbf{acc} if and only if
    \[ e(\cm/\textbf{C}(b),[1]_2)=e(w,[\tau-a]_2) \]
\end{enumerate}
\end{definition}
This does not violate the soundness of the original KZG commitment scheme. Note $\textbf{C}(b)$ is a Pedersen commitment. Recall the computational binding property of Pedersen commitment, that means it is infeasible for $\prv$ to compute a $b^*$ such that $f(a)\ne{b^*},\textbf{C}(b)=\textbf{C}(b^*)$ based on discrete logarithm assumption.
\begin{theorem}
\label{thm:kzgOpen}
$\openc$ is complete, sound, and special HVZK.
\end{theorem}
\begin{proof}
Completeness and soundness follow the original KZG commitment scheme.

To prove special HVZK, let the simulator $\mathcal{S}$ take as inputs $\textbf{srs}$, $\cm_f$, $a$, and $\textbf{C}(b)$. Since $\mathcal{S}$ knows the random evaluation point $a$ in advance, $\mathcal{S}$ can compute a witness $w^*=\cm_f/\textbf{C}(b)/[\tau-a]_1$ that makes the pairing equation hold, i.e., $\mathcal{S}$ always outputs an accepting conversation $(\cm_f,a,w^*)$ for $\textbf{C}(b)$.
\end{proof}
Back to the above range proof, now $\prv$ is able to prove $w_1$ is correct with \openc in zero-knowledge while using the zero-knowledge extension to prove $w_2$ and $w_3$ are correct. Together, we can prove a value $x$ is in the specified range without revealing $x$. We use $\openc(f,a)$ to denote opening the committed evaluation of $f(a)$.

% = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =