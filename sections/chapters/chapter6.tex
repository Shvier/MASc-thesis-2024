\chapter{Performance Evaluation}

\section{Theoretical Performance}

In this section, we anaylze the performance of \Sys, and compare the performance of our work with other prior schemes. Our analysis ignores the relatively trivial cost like Fast Fourier Transform (FFT) and focuses on the heavy work such as multi-scalar multiplication (MSM) and group operations. Our analysis also ignores the differences of the implementations and assumes each protocol is executed in a single thread.
\subsection{Proof of Assets}

We use $\kappa$ to denote the size of the anonymity set and we assume $\kappa$ is the power of two for simplicity. The performance analysis of \bootstrap and \userproof are performed as follows:
\begin{itemize}
\item \bootstrap: For each public key in the anonymity set, $\prv$ opens an evaluation of the KZG commitment and generates the corresponding proof of the $\Sigma$-protocol in Protocol~\ref{alg:boot}. When opening an evaluation of a KZG commitment, one MSM for the witness and one MSM for the blinding polynomial are involved. The number of scalar multiplications of the $\Sigma$-protocol is constant. Thus, the overhead proving time of \bootstrap is $O(\kappa^2)$. In terms of verifier's work, $\vrf$ does not need to perform MSM to verify the proofs; $\vrf$ computes scalar multiplications for constant times instead. To verify the committed values are correct, $\vrf$ manipulates the batched KZG scheme rather than verifying each proof one by one, which means $O(1)$ verifying time and proof size for each public key. Therefore, the overhead verifying time and proof size of \bootstrap is $O(\kappa)$.
\item \poa: $\prv$ constructs the accumulator and commits to constant number of polynomials. According to Schwartz-Zippel lemma, $\prv$ only needs to open one point of each polynomial. Thus, the proving time is $O(\kappa)$ and the proof size is $O(1)$ because the number of polynomial commitments is constant. While it takes constant time for $\vrf$ to verify the proof of the PCS, $\vrf$ needs to process the inputs, \ie interpolates the balances and commits to the balance polynomial, which means one MSM involved. Therefore, the overhead verifier's work of \poa is $O(\kappa)$.
\end{itemize}

\subsection{Proof of Liability}
We use $\mu$ to denote the number of users and $k$ to denote the allowed size of the range proof. Recall that $\prv$ needs to construct several polynomials for the range proof. Although the number of the range-proof polynomials is arbitrary, $2^{64}$ is sufficient for almost all the exchanges' requirements in the real world, which means there are less than or equal to 64 polynomials for the range proof. Therefore, we can treat the number of range-proof polynomials as a constant, but we still use $k$ to indicate the performance is related to the range proof. $\prv$ also needs to compute the accumulative polynomial to prove the total liablity is correct, which can be done in linear time. Different from \bootstrap, $\prv$ only opens each polynomial at one random evaluation point. Thus, the proving time is $O(\mu)$.
The verifier's work is broken into \userproof and \pol:
\begin{itemize}
\item \userproof: Each user verifies his balance is the evaluation of the polynomial $p_1$ and his user identifier is the evaluation of the polynomial $f_\mathsf{uid}$, and the two evaluation points should be the same. The user checks two proofs of KZG commitment, so the proof size and the verifying time for customers are both $O(1)$.
\item \pol: Auditor verifies the constraints among polynomials $\{p_i\}$ are correct and the committed total liablity is the evaluation of $f_\mathsf{liab}(\omega^0)$. The verification of constraints requires two steps: 1. validating each opening evaluation is correct; 2. the evaluations of $\{w_1,w_2,v_1,v_2,\dots,v_k\}$ are zero. The first step can be done in constant time because the number of polynomials is related to the range proof rather than the number of users. The second step takes several scalar multiplications and group additions but still in constant times. Recall that the proof of KZG commitment consists of one witness, one evaluation, and the corresponding evaluation point, which are unrelated to the degree of the polynomial. That means the verifying time and the proof size for auditors are both $O(k)$.
\end{itemize}

\subsection{Comparison}

\input{sections/tables/complexity}

In Table~\ref{tab:poa}, we compare this work with other prior PoA schemes. Both IZPR and this work utilize bootstrapping, but the bootstrapping of IZPR will be introduced in their following paper. We only analyze the performance of the bootstrapping for this work. In Table~\ref{tab:pol}, we compare this work with prior PoL schemes.

\section{Implementation and Benchmark Methodology}

\input{sections/tables/figures}

\input{sections/tables/figures}

To evaluate the performance of \Sys, we implemented our protocols in Rust based on the popular library, arkworks\footnote{\url{https://github.com/arkworks-rs}}. Our implementation is publicly accessible on GitHub\footnote{GitHub: link removed for anonymity. Can supply code via the program chairs as necessary.}. We chose the pairing-friendly elliptic curve \bls for the KZG commitment which has 128 bit security.

Our experiments were conducted on a personal computer with i9-13900KF and 32GB of memory. The experimental data including balances and \secp key pairs are randomly generated locally for simplicity. Since there is no range-proof for PoA, we tested the PoA with balances randomly distributed in $[1,2^{64})$ to simulate the real distribution of assets, and for PoL, we tested the program with balances randomly distributed in $[1,2^8)$, $[1,2^{16})$, $[1,2^{32})$, and $[1,2^{64})$. We simulated $2^8,2^9\dots,2^{14}$ and $2^{10},2^{11},\dots,2^{20}$ users for PoA and PoL respectively. Simulating different number of users for PoA and PoL is because \bootstrap was time-consuming for larger number of users. For each protocol, we ran the test for ten times with the same experimental data. Our figures are interpolated from the average performance of ten times with discarding the maximum and minimum of the samples.

\section{Experimental Evaluation}
Figure 2, 3, and 4 reflect the performance of \Sys in single thread with i9-13900KF. The Subfigure (a) of Figure 2 suggests it takes around 600 seconds to generate the proofs for 16,384 keys with i9-13900KF for \bootstrap, and the proof size is 13,893KB. There are around $2^{28}$ unique Ethereum addresses reported by Ethercan.io in May 2024 \footnote{\url{https://etherscan.io/chart/address}}, which means it requires 9,830,400 computing instances to generate the proofs for all the keys in 600 seconds if the exchange wants the maximum anonymous set. It seems impractical for the exchange to deploy such number of servers in the real world. However, recall the exchange only needs to perform \bootstrap once. The exchange can sacrifice the proving time to reduce the number of servers. Moreover, the proving time can be reduced significantly if manipulating more efficient KZG opening schemes. See Section~\ref{sec:opt} for more detailed optimizations. 

Figure 3 shows the proving time and the verifying time are linear in the number of the keys. In our experiments, it takes 433.66 milliseconds to generate the proof and 37.57 milliseconds to verify the proof for 16,384 keys. This suggests the proving time is less than 2 hours if the anonymous set is the whole addresses on Ethereum without any other optimizations! Since the proof size of a KZG commitment is unrelated to the degree of the polynomial (the number of keys), the proof size of \poa is constant (2KB) based on our implementation.

Figure 4 illustrates the performance of our PoL with different number of users and allowed ranges for balance. Our experiments show the proving time grows linearly by the number of users while the verifying time and the proof size are constant. From the test result of Binance's PoL, it needs 1.5 days to generate the proof for 100 million accounts with 100 servers \footnote{\url{https://github.com/binance/zkmerkle-proof-of-solvency/?tab=readme-ov-file}}, but our PoL requires less than 10 minutes with the same number of servers. This indicates our protocol is practical to handle the real-world applications.

\section{Optimization}
\label{sec:opt}
Due to the additively homomorphic property of KZG commitment, the prover's work in our protocols can be easily splitted to arbitrary number of servers, and there is no need to provide extra proofs to aggregate the proofs from different servers (provers). That means the proving time will decrease with the growing number of servers. This is the most direct method to make the protocols more efficient. Another way to improve the performance without adding more servers is utilizing more efficient KZG opening schemes. Recall the heaviest work of \bootstrap is proving each committed point is correct, and the opening scheme we demonstrated from Plonk requires $t\cdot{d}$ scalar multiplications for prover, where $t$ is the number of the opening points and $d$ is the degree bound of the polynomial. The work in BDFG20~\cite{bdfg} can reduce this complexity to $2n$ scalar multiplications, which means the dominating complexity will become $O(n)$ rather than $O(n^2)$. The aggreation slightly increases the verifier's work but the extra cost is trivial because of the succinctness of KZG commitment scheme. These optimizations can be applied to both of our PoA and PoL. Moreover, the proof length for multiple points of the KZG commitment will also be decreased to $O(1)$ if BDFG20 is intergated, but the total proof length is still $O(n)$ because of the proof of the $\Sigma$-protocol.

% = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =